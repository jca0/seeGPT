{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d00e81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940f6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('conversations.json', 'r') as f:\n",
    "    conversations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ed23d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msg(convo):\n",
    "    mapping = convo['mapping']\n",
    "    user_msgs = []\n",
    "    \n",
    "    for node in mapping.keys():\n",
    "        if mapping[node]['message']:\n",
    "            if 'parts' in mapping[node]['message']['content'].keys() and mapping[node]['message']['author']['role'] == 'user':\n",
    "                if isinstance(mapping[node]['message']['content']['parts'][0], str):\n",
    "                    user_msgs.append(mapping[node]['message']['content']['parts'])\n",
    "    return user_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4acd6bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3261/3261 [00:00<00:00, 117873.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_user_msgs = []\n",
    "for user_msg in tqdm(conversations):\n",
    "    all_user_msgs.extend(get_msg(user_msg))\n",
    "\n",
    "len(all_user_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0692da77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14108"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def clean_msg(msg, max_length=MAX_CONTEXT_LENGTH, embedding_model=EMBEDDING_MODEL):\n",
    "    msg = msg[0]\n",
    "    if len(msg) == 0: # empty message\n",
    "        return None\n",
    "    encoding = tiktoken.encoding_for_model(embedding_model)\n",
    "    tokens = encoding.encode(msg, disallowed_special=set())\n",
    "    if len(tokens) > max_length:\n",
    "        tokens = tokens[-max_length:]\n",
    "    return encoding.decode(tokens)\n",
    "\n",
    "texts_to_embed = []\n",
    "for msg in all_user_msgs:\n",
    "    cleaned_msg = clean_msg(msg)\n",
    "    if cleaned_msg:\n",
    "        texts_to_embed.append(cleaned_msg)\n",
    "\n",
    "len(texts_to_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e727db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches: 100%|██████████| 283/283 [03:04<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings: 14108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50 # worst case only set to 35\n",
    "\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(texts_to_embed), BATCH_SIZE), desc=\"Embedding batches\"):\n",
    "    batch = texts_to_embed[i:i+BATCH_SIZE]\n",
    "    try:\n",
    "        response = client.embeddings.create(input=batch, model=EMBEDDING_MODEL)\n",
    "        batch_embeddings = [data.embedding for data in response.data]\n",
    "        embeddings.extend(batch_embeddings)\n",
    "    except Exception as e:\n",
    "        print(f\"Error embedding batch {i}: {e}\")\n",
    "        break\n",
    "\n",
    "print(f\"Total embeddings: {len(embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e07ee819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering, HDBSCAN\n",
    "\n",
    "# kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "# kmeans.fit(embeddings)\n",
    "# labels = kmeans.labels_\n",
    "\n",
    "# spectral_clustering = SpectralClustering(n_clusters=5, affinity='nearest_neighbors', random_state=42)\n",
    "# spectral_clustering.fit(embeddings)\n",
    "# labels = spectral_clustering.labels_\n",
    "\n",
    "hdbscan = HDBSCAN(min_cluster_size=30, metric='cosine', cluster_selection_method='eom')\n",
    "hdbscan.fit(embeddings)\n",
    "labels = hdbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "750d607d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster -1 has 12964 messages\n",
      "Cluster 0 has 57 messages\n",
      "Cluster 1 has 30 messages\n",
      "Cluster 2 has 35 messages\n",
      "Cluster 3 has 49 messages\n",
      "Cluster 4 has 39 messages\n",
      "Cluster 5 has 170 messages\n",
      "Cluster 6 has 94 messages\n",
      "Cluster 7 has 66 messages\n",
      "Cluster 8 has 82 messages\n",
      "Cluster 9 has 35 messages\n",
      "Cluster 10 has 38 messages\n",
      "Cluster 11 has 84 messages\n",
      "Cluster 12 has 35 messages\n",
      "Cluster 13 has 34 messages\n",
      "Cluster 14 has 230 messages\n",
      "Cluster 15 has 66 messages\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "hdbscan_label_mapping = {}\n",
    "\n",
    "for label in np.unique(labels):\n",
    "    indices = np.where(labels == label)[0]\n",
    "    messages = [all_user_msgs[i][0] for i in indices]\n",
    "    hdbscan_label_mapping[label] = messages\n",
    "\n",
    "for label in sorted(hdbscan_label_mapping.keys()):\n",
    "    count = len(hdbscan_label_mapping[label])\n",
    "    if label == -1:\n",
    "        print(f\"Cluster {label} has {count} messages\")\n",
    "    else:\n",
    "        print(f\"Cluster {label} has {count} messages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cb50a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:46<00:00,  6.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{-1: 'Palantir interview prep',\n",
       " 0: 'Semantic navigation with LLMs',\n",
       " 1: 'RISC-V Instruction Decoder',\n",
       " 2: 'Machine learning optimization',\n",
       " 3: 'Q-learning Implementation',\n",
       " 4: 'DynamoDB to OpenSearch',\n",
       " 5: 'Bluespec CPU pipeline',\n",
       " 6: 'Robotics software development',\n",
       " 7: 'Code debugging help',\n",
       " 8: 'Cluster name: Code Debugging',\n",
       " 9: 'ROS2 Gazebo Troubleshooting',\n",
       " 10: 'Programming Debugging Challenges',\n",
       " 11: 'Code debugging questions',\n",
       " 12: 'Bitonic sorting networks',\n",
       " 13: 'Multi-domain Q&A',\n",
       " 14: 'LLM-guided indoor navigation',\n",
       " 15: 'ROS2 Navigation Visualization'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "all_cluster_info = []\n",
    "cluster_summaries = {i : None for i in hdbscan_label_mapping.keys()}\n",
    "\n",
    "for i in tqdm(sorted(hdbscan_label_mapping.keys())):\n",
    "    cluster_msgs = hdbscan_label_mapping[i][:300]\n",
    "    cluster_msgs_text = \" | \".join([msg for msg in cluster_msgs])\n",
    "    prompt = f\"\"\"You are analyzing a cluster of similar user messages. Based on the examples below, create a concise descriptive label (2-4 words) that captures the main topic or theme.\n",
    "\n",
    "        Messages in this cluster:\n",
    "        {cluster_msgs_text}\n",
    "\n",
    "        Instructions:\n",
    "        - Identify the common theme or topic\n",
    "        - Use 2-4 words\n",
    "        - Be specific and descriptive\n",
    "        - Return only the label name\n",
    "\n",
    "        Cluster name:\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    output = response.choices[0].message.content\n",
    "    cluster_summaries[i] = output\n",
    "\n",
    "cluster_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2dc7b2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: LLM-assisted indoor navigation research paper drafting\n",
      "Cluster 1: RISC-V decoding & HDL debugging\n",
      "Cluster 2: Advanced math/CS prompts (linear algebra and optimization)\n",
      "Cluster 3: CS interview prep & coding error debugging\n",
      "Cluster 4: Robotics research projects & assets data wrangling\n",
      "Cluster 5: CPU pipeline fetch/decode and hardware design debugging\n",
      "Cluster 6: Robotics startup grant idea development & competitive landscape\n",
      "Cluster 7: Robotics design writing and impedance control question\n",
      "Cluster 8: Traveling Repairman DP and AI writing prompts\n",
      "Cluster 9: ROS2 map setup and navigation debugging\n",
      "Cluster 10: KNN coding & probability/inference exercises\n",
      "Cluster 11: Differential equations and linear algebra fundamentals\n",
      "Cluster 12: Linguistics concepts + outreach writing\n",
      "Cluster 13: Danish syntax and English sentence structure analysis\n",
      "Cluster 14: Control theory, disturbances, SPL, and project ideation\n",
      "Cluster 15: AB-MCTS frontier AI research blog overview\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "tsne_result = tsne.fit_transform(embeddings)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
