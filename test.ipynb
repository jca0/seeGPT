{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d00e81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "940f6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('conversations.json', 'r') as f:\n",
    "    conversations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21ed23d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msg(convo):\n",
    "    mapping = convo['mapping']\n",
    "    user_msgs = []\n",
    "    \n",
    "    for node in mapping.keys():\n",
    "        if mapping[node]['message']:\n",
    "            if 'parts' in mapping[node]['message']['content'].keys() and mapping[node]['message']['author']['role'] == 'user':\n",
    "                if isinstance(mapping[node]['message']['content']['parts'][0], str):\n",
    "                    user_msgs.append(mapping[node]['message']['content']['parts'])\n",
    "    return user_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4acd6bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3261/3261 [00:00<00:00, 132211.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14157"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_user_msgs = []\n",
    "for user_msg in tqdm(conversations):\n",
    "    all_user_msgs.extend(get_msg(user_msg))\n",
    "\n",
    "len(all_user_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "embeddings = []\n",
    "\n",
    "for t in tqdm(all_user_msgs):\n",
    "    string_t = t[0]\n",
    "    embedding = tiktoken.encoding_for_model(EMBEDDING_MODEL).encode(string_t)\n",
    "    num_tokens = len(embedding)\n",
    "    try:\n",
    "        if num_tokens > MAX_CONTEXT_LENGTH:\n",
    "            string_t = string_t[-MAX_CONTEXT_LENGTH:]\n",
    "        embedding = client.embeddings.create(input=string_t, model=EMBEDDING_MODEL).data[0].embedding\n",
    "        embeddings.append(embedding)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0692da77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14108"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MAX_CONTEXT_LENGTH = 8192\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def clean_msg(msg, max_length=MAX_CONTEXT_LENGTH, embedding_model=EMBEDDING_MODEL):\n",
    "    msg = msg[0]\n",
    "    if len(msg) == 0: # empty message\n",
    "        return None\n",
    "    encoding = tiktoken.encoding_for_model(embedding_model)\n",
    "    tokens = encoding.encode(msg, disallowed_special=set())\n",
    "    if len(tokens) > max_length:\n",
    "        tokens = tokens[-max_length:]\n",
    "    return encoding.decode(tokens)\n",
    "\n",
    "texts_to_embed = []\n",
    "for msg in all_user_msgs:\n",
    "    cleaned_msg = clean_msg(msg)\n",
    "    if cleaned_msg:\n",
    "        texts_to_embed.append(cleaned_msg)\n",
    "\n",
    "len(texts_to_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11e727db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches: 100%|██████████| 283/283 [03:45<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings: 14108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50 # worst case only set to 35\n",
    "\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(texts_to_embed), BATCH_SIZE), desc=\"Embedding batches\"):\n",
    "    batch = texts_to_embed[i:i+BATCH_SIZE]\n",
    "    try:\n",
    "        response = client.embeddings.create(input=batch, model=EMBEDDING_MODEL)\n",
    "        batch_embeddings = [data.embedding for data in response.data]\n",
    "        embeddings.extend(batch_embeddings)\n",
    "    except Exception as e:\n",
    "        print(f\"Error embedding batch {i}: {e}\")\n",
    "        break\n",
    "\n",
    "print(f\"Total embeddings: {len(embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e07ee819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, init='k-means++', random_state=42)\n",
    "kmeans.fit(embeddings)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "text_label_mapping = {i: [] for i in range(5)}\n",
    "for text, label in zip(texts_to_embed, labels):\n",
    "    text_label_mapping[label].append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1f70bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1770, 1: 5130, 2: 2735, 3: 2917, 4: 1556}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sizes = {i: len(text_label_mapping[i]) for i in text_label_mapping.keys()}\n",
    "cluster_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1cb50a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cluster 0: RL/Control Coding Help\\nCluster 1: STEM Q&A and LaTeX\\nCluster 2: Cloud GPU Troubleshooting\\nCluster 3: Career/Writing Refinement\\nCluster 4: Robotics Research Ideas'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Process all clusters in fewer API calls\n",
    "all_cluster_info = []\n",
    "\n",
    "for i in sorted(text_label_mapping.keys()):\n",
    "    examples = text_label_mapping[i][:100]\n",
    "    examples_text = \" | \".join([ex for ex in examples])\n",
    "    all_cluster_info.append(f\"Cluster {i}: {examples_text}\")\n",
    "\n",
    "prompt = f\"\"\"I have clustered user messages into groups. For each cluster below, provide a short descriptive name (2-4 words).\n",
    "\n",
    "{chr(10).join(all_cluster_info)}\n",
    "\n",
    "Respond in the format:\n",
    "Cluster 0: [name]\n",
    "Cluster 1: [name]\n",
    "etc.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "tsne_result = tsne.fit_transform(embeddings)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "581e22f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>class LinearPolicy(nn.Module):\\n    def __init__(self, in_dim, out_dim):\\n        super(LinearPolicy, self).__init__()\\n        self.Linear = nn.Linear(in_dim, out_dim)\\n\\n    def forward(self, ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>class LinearPGNetwork(nn.Module):\\n    def __init__(self, in_dim=4, out_dim=2):\\n        super().__init__()\\n        self.linear = nn.Linear(in_dim, out_dim, bias=True)\\n\\n    def forward(self, ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>def print_linear_coeffs(model):\\n    with torch.no_grad():\\n        A = model.linear.weight.detach().cpu().numpy()\\n        b = model.linear.bias.detach().cpu().numpy()\\n    w = A[1] - A[0]\\n    c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>what's the difference between software engineer and forward deployment software engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>why swe over fdse?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>i don't get it, what are arms?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>how do i write text into the links file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>how do i uninstall tauri from my mac. i downloaded it from my terminal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Original custom instructions no longer available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>how do i build a personal dashboard that tells me how i've been using ChatGPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>how long does it take to receive the email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>expand on this more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>how do i build a personal dashboard that tells me how i've been using AI tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>building smarter robots. but not by dumping more training data or building larger end-to-end models. i want make robots smarter by mimicking how people think. when humans learn from watching someo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>Palantir's work on empowering data-driven decisions across crucial industries, from healthcare to defense, is incredibly exciting. Palantir's solutions stand out because they are designed to trans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cluster                                                                                                                                                                                                  Example\n",
       "0         0  class LinearPolicy(nn.Module):\\n    def __init__(self, in_dim, out_dim):\\n        super(LinearPolicy, self).__init__()\\n        self.Linear = nn.Linear(in_dim, out_dim)\\n\\n    def forward(self, ob...\n",
       "1         0  class LinearPGNetwork(nn.Module):\\n    def __init__(self, in_dim=4, out_dim=2):\\n        super().__init__()\\n        self.linear = nn.Linear(in_dim, out_dim, bias=True)\\n\\n    def forward(self, ob...\n",
       "2         0  def print_linear_coeffs(model):\\n    with torch.no_grad():\\n        A = model.linear.weight.detach().cpu().numpy()\\n        b = model.linear.bias.detach().cpu().numpy()\\n    w = A[1] - A[0]\\n    c...\n",
       "3         1                                                                                                                 what's the difference between software engineer and forward deployment software engineer\n",
       "4         1                                                                                                                                                                                       why swe over fdse?\n",
       "5         1                                                                                                                                                                           i don't get it, what are arms?\n",
       "6         2                                                                                                                                                                  how do i write text into the links file\n",
       "7         2                                                                                                                                   how do i uninstall tauri from my mac. i downloaded it from my terminal\n",
       "8         2                                                                                                                                                         Original custom instructions no longer available\n",
       "9         3                                                                                                                            how do i build a personal dashboard that tells me how i've been using ChatGPT\n",
       "10        3                                                                                                                                                               how long does it take to receive the email\n",
       "11        3                                                                                                                                                                                      expand on this more\n",
       "12        4                                                                                                                           how do i build a personal dashboard that tells me how i've been using AI tools\n",
       "13        4  building smarter robots. but not by dumping more training data or building larger end-to-end models. i want make robots smarter by mimicking how people think. when humans learn from watching someo...\n",
       "14        4  Palantir's work on empowering data-driven decisions across crucial industries, from healthcare to defense, is incredibly exciting. Palantir's solutions stand out because they are designed to trans..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table_data = []\n",
    "\n",
    "# show examples of each cluster\n",
    "for label in sorted(text_label_mapping.keys()):\n",
    "    examples = text_label_mapping[label][:3]\n",
    "    for i, example in enumerate(examples):\n",
    "        table_data.append({\n",
    "            'Cluster': label,\n",
    "            'Example': example,\n",
    "        })\n",
    "\n",
    "df_examples = pd.DataFrame(table_data)\n",
    "\n",
    "df_examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
